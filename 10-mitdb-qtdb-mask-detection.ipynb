{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8dd3107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:07.183345Z",
     "iopub.status.busy": "2025-05-26T10:17:07.182396Z",
     "iopub.status.idle": "2025-05-26T10:17:11.786757Z",
     "shell.execute_reply": "2025-05-26T10:17:11.786008Z"
    },
    "id": "roZgmsPyFKjB",
    "outputId": "7ace9a87-c359-42a4-e43c-bc2a5afe7715",
    "papermill": {
     "duration": 4.612315,
     "end_time": "2025-05-26T10:17:11.788431",
     "exception": false,
     "start_time": "2025-05-26T10:17:07.176116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install wfdb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22829d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:11.800083Z",
     "iopub.status.busy": "2025-05-26T10:17:11.799793Z",
     "iopub.status.idle": "2025-05-26T10:17:14.673401Z",
     "shell.execute_reply": "2025-05-26T10:17:14.672481Z"
    },
    "id": "L5ge4LwBPcr6",
    "papermill": {
     "duration": 2.880727,
     "end_time": "2025-05-26T10:17:14.674944",
     "exception": false,
     "start_time": "2025-05-26T10:17:11.794217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wfdb\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3480e0f",
   "metadata": {
    "id": "ZTMmDNHCfhhu",
    "papermill": {
     "duration": 0.00489,
     "end_time": "2025-05-26T10:17:14.684761",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.679871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fec7df",
   "metadata": {
    "id": "jvXrP01oftqo",
    "papermill": {
     "duration": 0.004733,
     "end_time": "2025-05-26T10:17:14.694011",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.689278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## preprocess Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2411c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.704872Z",
     "iopub.status.busy": "2025-05-26T10:17:14.704006Z",
     "iopub.status.idle": "2025-05-26T10:17:14.710841Z",
     "shell.execute_reply": "2025-05-26T10:17:14.710258Z"
    },
    "id": "JNp2geUV6p_G",
    "papermill": {
     "duration": 0.013434,
     "end_time": "2025-05-26T10:17:14.712110",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.698676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "def bandpass_filter(signal, fs=250, lowcut=0.5,  highcut=15.0,  order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "    \n",
    "def smooth_signal(data, window_size=5):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    smoothed = np.convolve(data, window, mode='same')\n",
    "    return smoothed\n",
    "def normalize_signal(data):\n",
    "    return (data - np.mean(data)) / np.std(data)\n",
    "\n",
    "def resample_signal(signal, original_fs, target_fs):\n",
    "    num_samples = int(len(signal) * target_fs / original_fs)\n",
    "    resampled_signal = resample(signal, num_samples)\n",
    "    return resampled_signal\n",
    "def adjust_annotations(samples, original_fs, target_fs):\n",
    "    scale = target_fs / original_fs\n",
    "    if isinstance(samples, (list, np.ndarray)):\n",
    "        return (np.array(samples) * scale).astype(int)\n",
    "    else:\n",
    "        return int(samples * scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67d7af",
   "metadata": {
    "id": "ZW-HQbGIN86a",
    "papermill": {
     "duration": 0.004609,
     "end_time": "2025-05-26T10:17:14.721577",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.716968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d84f5ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.731507Z",
     "iopub.status.busy": "2025-05-26T10:17:14.731295Z",
     "iopub.status.idle": "2025-05-26T10:17:14.737176Z",
     "shell.execute_reply": "2025-05-26T10:17:14.736492Z"
    },
    "id": "Fd5btn-3IGM1",
    "papermill": {
     "duration": 0.012104,
     "end_time": "2025-05-26T10:17:14.738302",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.726198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_full_ecg(signal, model, fs=250, window_size=240):\n",
    "    model.eval()\n",
    "    signal = signal[:len(signal) - (len(signal) % window_size)]  # crop to multiple of window_size\n",
    "    signal = normalize_signal(smooth_signal(bandpass_filter(signal, fs=fs)))\n",
    "    if fs != 250:\n",
    "        signal = resample_signal(signal, original_fs=fs, target_fs=250)\n",
    "        fs = fs\n",
    "    signal = signal.reshape(1, 1, -1)  # (1, 1, L)\n",
    "\n",
    "    segments = []\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0, signal.shape[2] - window_size + 1, window_size):\n",
    "        window = signal[:, :, i:i+window_size]\n",
    "        segments.append(window)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for window in segments:\n",
    "            window = torch.tensor(window, dtype=torch.float32).to(device)\n",
    "            output = model(window)  # (1, C, L)\n",
    "            pred = torch.argmax(output, dim=1).cpu().numpy()[0]  # (L,)\n",
    "            predictions.append(pred)\n",
    "\n",
    "    full_prediction = np.concatenate(predictions)\n",
    "    return full_prediction, segments, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b596a57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.748333Z",
     "iopub.status.busy": "2025-05-26T10:17:14.747784Z",
     "iopub.status.idle": "2025-05-26T10:17:14.753198Z",
     "shell.execute_reply": "2025-05-26T10:17:14.752444Z"
    },
    "id": "hqpbvUexIbT1",
    "papermill": {
     "duration": 0.011538,
     "end_time": "2025-05-26T10:17:14.754336",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.742798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_wave_boundaries(predicted_labels):\n",
    "    wave_types = {1: 'P', 2: 'QRS', 3: 'T'}\n",
    "    wave_boundaries = {k: [] for k in wave_types.values()}\n",
    "\n",
    "    current_class = None\n",
    "    start = None\n",
    "\n",
    "    for i, label in enumerate(predicted_labels):\n",
    "        if label in wave_types:\n",
    "            if current_class is None:\n",
    "                current_class = label\n",
    "                start = i\n",
    "            elif label != current_class:\n",
    "                wave_boundaries[wave_types[current_class]].append((start, i-1))\n",
    "                current_class = label\n",
    "                start = i\n",
    "        else:\n",
    "\n",
    "            if current_class is not None:\n",
    "                wave_boundaries[wave_types[current_class]].append((start, i-1))\n",
    "                current_class = None\n",
    "                start = None\n",
    "\n",
    "    # Handle last segment\n",
    "    if current_class is not None:\n",
    "        wave_boundaries[wave_types[current_class]].append((start, len(predicted_labels)-1))\n",
    "\n",
    "    return wave_boundaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13715b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.764321Z",
     "iopub.status.busy": "2025-05-26T10:17:14.764124Z",
     "iopub.status.idle": "2025-05-26T10:17:14.770590Z",
     "shell.execute_reply": "2025-05-26T10:17:14.769926Z"
    },
    "id": "KBxpb7yjQzg7",
    "papermill": {
     "duration": 0.012898,
     "end_time": "2025-05-26T10:17:14.771825",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.758927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_boundaries(signal, boundaries, signal_name, model_name, fs=250, zoom=(0, None)):\n",
    "    time = np.arange(len(signal)) / fs  # Convert indices to time (seconds)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.plot(time, signal, color='black', label='ECG Signal', linewidth=1)\n",
    "\n",
    "    wave_colors = {'P': 'blue', 'QRS': 'red', 'T': 'green'}\n",
    "    added_labels = set()\n",
    "\n",
    "    # Convert zoom limits to sample indices\n",
    "    zoom_start_idx = int(zoom[0] * fs)\n",
    "    zoom_end_idx = int(zoom[1] * fs) if zoom[1] is not None else len(signal)\n",
    "\n",
    "    for wave_type, regions in boundaries.items():\n",
    "        for start, end in regions:\n",
    "            # Only plot if within zoom range\n",
    "            if start >= zoom_start_idx and end <= zoom_end_idx:\n",
    "                label = f'Predicted {wave_type}' if wave_type not in added_labels else None\n",
    "                plt.fill_between(\n",
    "                    time[start:end],\n",
    "                    -1, 1,\n",
    "                    color=wave_colors.get(wave_type, 'gray'),\n",
    "                    alpha=0.3,\n",
    "                    label=label\n",
    "                )\n",
    "                added_labels.add(wave_type)\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f\"signal: {signal_name}, model: {model_name}\", fontsize=16)\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Apply zoom\n",
    "    plt.xlim(zoom[0], zoom[1] if zoom[1] is not None else time[-1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf466fa",
   "metadata": {
    "id": "UCgs5n5KgSse",
    "papermill": {
     "duration": 0.004178,
     "end_time": "2025-05-26T10:17:14.780567",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.776389",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Post-process Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52dd95d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.790616Z",
     "iopub.status.busy": "2025-05-26T10:17:14.790408Z",
     "iopub.status.idle": "2025-05-26T10:17:14.794603Z",
     "shell.execute_reply": "2025-05-26T10:17:14.794122Z"
    },
    "id": "kmS2kirJ8Jvn",
    "outputId": "741640e0-0117-4dfe-af6f-63ba631b3b53",
    "papermill": {
     "duration": 0.010427,
     "end_time": "2025-05-26T10:17:14.795710",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.785283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def remove_uncomplete_first_last_wave(predicted):\n",
    "    start = predicted[0]\n",
    "    end = predicted[-1]\n",
    "    if start != 0:\n",
    "      i=0\n",
    "      while i < len(predicted) and predicted[i]==start:\n",
    "        i+=1\n",
    "      predicted[:i]=0\n",
    "    if end != 0:\n",
    "      i=len(predicted)-1\n",
    "      while i > -1 and predicted[i]==end:\n",
    "        i-=1\n",
    "      predicted[i+1:]=0\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec4f6ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.805622Z",
     "iopub.status.busy": "2025-05-26T10:17:14.805415Z",
     "iopub.status.idle": "2025-05-26T10:17:14.809753Z",
     "shell.execute_reply": "2025-05-26T10:17:14.809294Z"
    },
    "id": "7e5D4ca1e68y",
    "outputId": "2235cdc7-183d-42ef-f842-be84ca20ebfe",
    "papermill": {
     "duration": 0.010581,
     "end_time": "2025-05-26T10:17:14.810819",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.800238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def merge_close_waves(predicted, max_gap=10):\n",
    "  predicted = predicted.copy()\n",
    "  for target_class in [1,2,3]:\n",
    "    indices = np.where(predicted == target_class)[0]\n",
    "\n",
    "    if len(indices) < 2:\n",
    "        return predicted  \n",
    "\n",
    "    for i in range(len(indices) - 1):\n",
    "        current = indices[i]\n",
    "        next_ = indices[i + 1]\n",
    "        if 0 < next_ - current - 1 < max_gap:\n",
    "            predicted[current:next_ + 1] = target_class\n",
    "\n",
    "\n",
    "\n",
    "  return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7c8332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.820737Z",
     "iopub.status.busy": "2025-05-26T10:17:14.820525Z",
     "iopub.status.idle": "2025-05-26T10:17:14.827043Z",
     "shell.execute_reply": "2025-05-26T10:17:14.826498Z"
    },
    "id": "TGZYAxZz8Ftk",
    "outputId": "af8d22cd-fd2c-4ff7-d957-9affa4a8d681",
    "papermill": {
     "duration": 0.012737,
     "end_time": "2025-05-26T10:17:14.828125",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.815388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_irrelevant_waves(predicted,start_search=2,end_search=5):\n",
    "    start=0\n",
    "    # Find the first P that has a QRS after it\n",
    "    if 1 in predicted[:start_search*250] :\n",
    "      for i in range(len(predicted)-1):\n",
    "          start = i\n",
    "\n",
    "          if predicted[i] == 1:\n",
    "              start = i\n",
    "              \n",
    "              while i < len(predicted)-1 and predicted[i] == 1:\n",
    "                i += 1\n",
    "              # if it's not 0 or 2 break\n",
    "              if predicted[i] == 3:\n",
    "                continue\n",
    "              # skip background if it exist\n",
    "              if predicted[i] == 0:\n",
    "                while i < len(predicted)-1 and predicted[i] == 0:\n",
    "                  i += 1\n",
    "              # if it's not qrs continue to next p\n",
    "              if predicted[i] != 2:\n",
    "                continue\n",
    "              else:\n",
    "                break\n",
    "      predicted[:start] = 0\n",
    "\n",
    "\n",
    "    # remove after last T\n",
    "    if 3 in predicted[-end_search*250:]:\n",
    "      \n",
    "      end = predicted[-1]\n",
    "      for i in range((len(predicted) - 1), -1, -1):\n",
    "          end = i\n",
    "\n",
    "          if predicted[i] == 3:\n",
    "              end = i\n",
    "              while i > 0 and predicted[i] == 3:\n",
    "                i -= 1\n",
    "              # if it's not 0 or 2 break\n",
    "              if predicted[i] == 1:\n",
    "                continue\n",
    "              # skip background if it exist\n",
    "              if predicted[i] == 0:\n",
    "                while i > 0 and predicted[i] == 0:\n",
    "                  i -= 1\n",
    "              # if it's not qrs continue to next t\n",
    "              if predicted[i] != 2:\n",
    "                continue\n",
    "              else:\n",
    "                break\n",
    "      predicted[end+1:] = 0\n",
    "\n",
    "    return (predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b200bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.838997Z",
     "iopub.status.busy": "2025-05-26T10:17:14.838813Z",
     "iopub.status.idle": "2025-05-26T10:17:14.844507Z",
     "shell.execute_reply": "2025-05-26T10:17:14.844045Z"
    },
    "id": "CSwwTMCAcJ7h",
    "outputId": "9c0e8129-f653-4b9f-8e4c-f1732f45e059",
    "papermill": {
     "duration": 0.012336,
     "end_time": "2025-05-26T10:17:14.845628",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.833292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_repeated_waves(predicted):\n",
    "    cleaned = predicted.copy()\n",
    "    for target_class in [1,2,3]:\n",
    "      segments = []\n",
    "      in_segment = False\n",
    "      start = 0\n",
    "\n",
    "      # Step 1: Collect all segments of the target class\n",
    "      for i, val in enumerate(predicted):\n",
    "          if val == target_class and not in_segment:\n",
    "              in_segment = True\n",
    "              start = i\n",
    "          elif val != target_class and in_segment:\n",
    "              in_segment = False\n",
    "              segments.append((start, i - 1))\n",
    "      if in_segment:\n",
    "          segments.append((start, len(predicted) - 1))\n",
    "\n",
    "      # Step 2: Check for pairs of segments with only background (0) in between\n",
    "      i = 0\n",
    "      while i < len(segments) - 1:\n",
    "          s1, e1 = segments[i]\n",
    "          s2, e2 = segments[i + 1]\n",
    "          between = cleaned[e1 + 1:s2]\n",
    "\n",
    "          if np.all(between == 0):  # Only background between them\n",
    "              len1 = e1 - s1 + 1\n",
    "              len2 = e2 - s2 + 1\n",
    "\n",
    "              # Remove the shorter one\n",
    "              if len1 < len2:\n",
    "                  cleaned[s1:e1 + 1] = 0\n",
    "              else:\n",
    "                  cleaned[s2:e2 + 1] = 0\n",
    "\n",
    "              # Remove the deleted segment from the list\n",
    "              segments.pop(i if len1 < len2 else i + 1)\n",
    "          else:\n",
    "              i += 1\n",
    "\n",
    "\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f931c25e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.856413Z",
     "iopub.status.busy": "2025-05-26T10:17:14.856227Z",
     "iopub.status.idle": "2025-05-26T10:17:14.871684Z",
     "shell.execute_reply": "2025-05-26T10:17:14.871126Z"
    },
    "id": "2GFazaNobuRe",
    "papermill": {
     "duration": 0.02277,
     "end_time": "2025-05-26T10:17:14.872813",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.850043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from tqdm import tqdm\n",
    "def fix_before_P(signal,mask,p_start,p_end,slope_threshold=0.02):\n",
    "  diff_signal = np.diff([signal[p_start],signal[p_start-5]])  # check around the Q point for slope change\n",
    "  j = 0\n",
    "  while True:\n",
    "    while np.abs(diff_signal[-1]) >= slope_threshold and signal[p_start]>signal[p_start-1] and mask[p_start-1]==0:  # Continue until slope becomes small\n",
    "        j+=1\n",
    "        p_start -= 1\n",
    "        mask[p_start] = 1  # mark as part of the QRS\n",
    "        diff_signal = np.diff([signal[p_start],signal[p_start-5]])  # re-evaluate slope\n",
    "    if mask[p_start-1]!=0:\n",
    "      break\n",
    "    if j == 0:\n",
    "\n",
    "        slope_threshold -= 0.001\n",
    "        #print(\"slope_threshold: \",slope_threshold)\n",
    "        if slope_threshold < 0.005:\n",
    "          break\n",
    "    else:\n",
    "        break\n",
    "  #print (\"fixed_before with peak:\",j)\n",
    "  return mask,p_start\n",
    "\n",
    "\n",
    "def fix_P(signal, mask):\n",
    "    p_mask = (mask == 1).astype(int)\n",
    "    qrs_mask = (mask == 2).astype(int)\n",
    "\n",
    "    transitions = np.diff(p_mask, prepend=0)\n",
    "    p_starts = np.where(transitions == 1)[0]\n",
    "\n",
    "    qrs_starts = np.where(np.diff(qrs_mask, prepend=0) == 1)[0]\n",
    "\n",
    "    fixed_p_info = []\n",
    "\n",
    "    for i in tqdm(range(len(p_starts)), desc=\"Processing P\"):\n",
    "\n",
    "        slope_threshold = 0.02  # arbitrary threshold for slope to be considered small\n",
    "        p_start = p_starts[i]\n",
    "\n",
    "        p_next = p_starts[i+1] if i < len(p_starts) - 1 else len(mask)\n",
    "        p_indices = np.where((mask == 1) & (np.arange(len(mask)) >= p_start) & (np.arange(len(mask)) < p_next))[0]\n",
    "\n",
    "        p_end = p_indices[-1] if  len(p_indices)>0 else p_start\n",
    "        #print(\"p_start,p_end: \",p_start,p_end)\n",
    "        # Get indices of current P segment\n",
    "        if len(p_indices) < 3:\n",
    "            continue\n",
    "\n",
    "        p_wave = signal[p_indices]\n",
    "\n",
    "        # Check for peak inside current P segment\n",
    "        peaks, _ = find_peaks(p_wave, prominence=0.01)\n",
    "        has_peak = len(peaks) > 0\n",
    "        peak_index = p_indices[peaks[0]] if has_peak else None\n",
    "\n",
    "        # If no peak, look after end of P segment\n",
    "        post_p_peak_index = None\n",
    "        if has_peak:\n",
    "          #print(\"has peak\")\n",
    "          mask, p_start = fix_before_P(signal, mask,p_start,p_end)\n",
    "          j=0\n",
    "          #print(p_end)\n",
    "          while (p_end + 1 < len(signal)) and signal[p_end] > signal[p_start] and mask[p_end + 1] == 0:\n",
    "            j += 1\n",
    "            p_end += 1\n",
    "            mask[p_end] = 1\n",
    "        if not has_peak:\n",
    "\n",
    "            # Look ahead to the next QRS start\n",
    "            next_qrs_start = qrs_starts[qrs_starts > p_end]\n",
    "            next_qrs_start = next_qrs_start[0] if len(next_qrs_start) > 0 else len(signal)\n",
    "\n",
    "            # Look AFTER the P segment\n",
    "            post_range = np.arange(p_start,min(len(signal) ,p_end + 50,  next_qrs_start ))\n",
    "            post_peaks = []\n",
    "            if len(post_range) > 3:\n",
    "                post_wave = signal[post_range]\n",
    "                peaks, _ = find_peaks(post_wave, prominence=0.01)\n",
    "                # Filter by mask == 0\n",
    "                for p in peaks:\n",
    "                    peak_idx = post_range[p]\n",
    "                    # Check that the region from p_end to peak_idx is all mask == 0\n",
    "                    if np.all(mask[p_end+1:peak_idx + 1] == 0):\n",
    "                        post_peaks.append(peak_idx)\n",
    "\n",
    "\n",
    "            # Look BEFORE the P segment\n",
    "            pre_range = np.arange(max(0, p_start - 50), p_end)  # limit the look-back window to ~400ms\n",
    "            pre_peaks = []\n",
    "            if len(pre_range) > 3:\n",
    "                pre_wave = signal[pre_range]\n",
    "                peaks, _ = find_peaks(pre_wave, prominence=0.01)\n",
    "                # Filter by mask == 0\n",
    "                pre_peaks = [pre_range[p] for p in peaks if mask[pre_range[p]] == 0]\n",
    "                for p in peaks:\n",
    "                    peak_idx = pre_range[p]\n",
    "                    # Check that the region from p_end to peak_idx is all mask == 0\n",
    "                    if np.all(mask[peak_idx + 1:p_start] == 0):\n",
    "                        pre_peaks.append(peak_idx)\n",
    "\n",
    "            # Closest peak\n",
    "            ## Combine both and choose closest properly\n",
    "            closest_peak = None\n",
    "            min_distance = float('inf')\n",
    "\n",
    "            ## Compare post-peaks to p_end\n",
    "            for peak in post_peaks:\n",
    "                dist = abs(peak - p_end)\n",
    "                if dist < min_distance:\n",
    "                    min_distance = dist\n",
    "                    closest_peak = peak\n",
    "\n",
    "            ## Compare pre-peaks to p_start\n",
    "            for peak in pre_peaks:\n",
    "                dist = abs(peak - p_start)\n",
    "                if dist < min_distance:\n",
    "                    min_distance = dist\n",
    "                    closest_peak = peak\n",
    "\n",
    "            post_p_peak_index = closest_peak if closest_peak is not None else None\n",
    "\n",
    "            peak = None\n",
    "            if post_p_peak_index is not None:\n",
    "              if post_p_peak_index < p_start:\n",
    "                peak = \"before\"\n",
    "              else:\n",
    "                peak = \"after\"\n",
    "\n",
    "\n",
    "            #print(peak)\n",
    "            if peak == \"after\":\n",
    "                mask, p_start = fix_before_P(signal, mask,p_start,p_end)\n",
    "                j=0\n",
    "                while (p_end + 1 < len(signal)) and signal[p_end] > signal[p_start] and mask[p_end + 1] == 0:\n",
    "                  j += 1\n",
    "                  p_end += 1\n",
    "                  mask[p_end] = 1\n",
    "            elif peak == \"before\":\n",
    "\n",
    "                mask[post_p_peak_index-2:p_start] = 1\n",
    "                p_start = post_p_peak_index-2\n",
    "                mask, p_start = fix_before_P(signal, mask,p_start,p_end)\n",
    "\n",
    "\n",
    "        fixed_p_info.append({\n",
    "            'start': p_indices[0],\n",
    "            'end': p_indices[-1],\n",
    "            'has_peak': has_peak,\n",
    "            'peak_index': peak_index,\n",
    "            'post_p_peak_index': post_p_peak_index\n",
    "        })\n",
    "        #print (fixed_p_info)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcb724f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.882801Z",
     "iopub.status.busy": "2025-05-26T10:17:14.882614Z",
     "iopub.status.idle": "2025-05-26T10:17:14.894628Z",
     "shell.execute_reply": "2025-05-26T10:17:14.894051Z"
    },
    "id": "ADTXHL6it3qJ",
    "papermill": {
     "duration": 0.018321,
     "end_time": "2025-05-26T10:17:14.895731",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.877410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fix_QRS(signal, mask, fs=250):\n",
    "    features_list = []\n",
    "    time = np.arange(len(signal)) / fs\n",
    "\n",
    "    # Find all QRS starts\n",
    "    qrs_mask = (mask == 2).astype(int)\n",
    "    transitions = np.diff(qrs_mask, prepend=0)\n",
    "    qrs_starts = np.where(transitions == 1)[0]\n",
    "    fixed_down = []\n",
    "    fixed_up = []\n",
    "    fixed_start = []\n",
    "\n",
    "    slope_threshold = 0.02  # arbitrary threshold for slope to be considered small\n",
    "    #print(len(qrs_starts))\n",
    "\n",
    "    for i in range(len( qrs_starts)):\n",
    "        #print(\"starting:\",i,\"/\",len( qrs_starts))\n",
    "        #print(\"fixing qrs \",i)\n",
    "        qrs_start = qrs_starts[i]\n",
    "        next_qrs_start = qrs_starts[i+1] if i < len(qrs_starts) - 1 else len(mask)\n",
    "        qrs_indices = np.where((mask == 2) & (np.arange(len(mask)) >= qrs_start) & (np.arange(len(mask)) < next_qrs_start))[0]\n",
    "        qrs_end = qrs_indices[-1]\n",
    "        j = 0\n",
    "\n",
    "        # QRS Begining\n",
    "\n",
    "        ## Searching for p\n",
    "        p_indices = np.where(mask[:qrs_start] == 1)[0]\n",
    "        valid_p = []\n",
    "        for p_end in reversed(p_indices):\n",
    "            if np.all(mask[p_end:qrs_start] != 2) and np.all(mask[p_end:qrs_start] != 3):\n",
    "                p_start = p_end\n",
    "                while p_start > 0 and mask[p_start - 1] == 1:\n",
    "                    p_start -= 1\n",
    "                valid_p = list(range(p_start, p_end + 1))\n",
    "                break\n",
    "        p_wave = signal[valid_p] if valid_p else np.array([])\n",
    "        p_indices = valid_p if valid_p else np.array([])\n",
    "        dist = qrs_start - p_indices[-1] if len(p_indices) > 0 else float('inf')\n",
    "        #  if p\n",
    "        if len(p_wave)>0 and dist < 20:\n",
    "          mask[p_indices[-1]+1:qrs_start] = 2\n",
    "          qrs_start = p_indices[-1]+1\n",
    "        else:\n",
    "\n",
    "          # Look BEFORE the QRS segment\n",
    "          pre_range = np.arange(max(0, qrs_start - 100), qrs_start)  # limit to ~400ms before\n",
    "          pre_peaks = []\n",
    "          if len(pre_range) > 3:\n",
    "              pre_wave = signal[pre_range]\n",
    "              peaks, _ = find_peaks(pre_wave, prominence=0.01)\n",
    "              pre_peaks = [pre_range[p] for p in peaks if mask[pre_range[p]] == 0]\n",
    "\n",
    "          # Track first peak (if any)\n",
    "          first_peak_before_qrs = pre_peaks[0] if pre_peaks else None\n",
    "\n",
    "          # Begin slope-based backtracking\n",
    "          j = 0\n",
    "          while True:\n",
    "              # Stop if slope is small\n",
    "              if qrs_start - 3 < 0: break\n",
    "              diff_signal = np.diff([signal[qrs_start], signal[qrs_start - 3]])\n",
    "\n",
    "              if np.abs(diff_signal[-1]) < slope_threshold:\n",
    "                  break\n",
    "\n",
    "              # Stop if we hit the first peak\n",
    "              if first_peak_before_qrs is not None and qrs_start <= first_peak_before_qrs:\n",
    "                  break\n",
    "\n",
    "              # Otherwise, continue extending the QRS\n",
    "              if mask[qrs_start - 1] != 0:\n",
    "                  break\n",
    "\n",
    "              j += 1\n",
    "              qrs_start -= 1\n",
    "              mask[qrs_start] = 2  # extend QRS\n",
    "\n",
    "              # Optional: decrease threshold if no progress\n",
    "              if j == 0:\n",
    "\n",
    "                  slope_threshold -= 0.001\n",
    "                  if slope_threshold<0: break\n",
    "\n",
    "\n",
    "        fixed_start.append(j)\n",
    "        # QRS ending\n",
    "\n",
    "        ## Before Q\n",
    "        while signal[qrs_end] >= signal[qrs_end+1] and mask[qrs_end+1]==0:\n",
    "\n",
    "            j+=1\n",
    "            qrs_end += 1\n",
    "            mask[qrs_end] = 2\n",
    "\n",
    "        fixed_down.append(j)\n",
    "\n",
    "        ## After Q\n",
    "        diff_signal = np.diff([signal[qrs_end],signal[qrs_end+5]])  # check around the Q point for slope change\n",
    "        j = 0\n",
    "        while True:\n",
    "          while np.abs(diff_signal[-1]) >= slope_threshold and mask[qrs_end+1]==0:  # Continue until slope becomes small\n",
    "              j+=1\n",
    "              qrs_end += 1\n",
    "              mask[qrs_end] = 2  # mark as part of the QRS\n",
    "              diff_signal = np.diff([signal[qrs_end],signal[qrs_end+5]])  # re-evaluate slope\n",
    "          if mask[qrs_end+1]!=0:\n",
    "            break\n",
    "          if j == 0:\n",
    "              slope_threshold -= 0.001\n",
    "              if slope_threshold<0.005: break\n",
    "          else:\n",
    "              break\n",
    "\n",
    "          #print (\"j: \",j)\n",
    "        fixed_up.append(j)\n",
    "\n",
    "\n",
    "    #print (\"fixed_down:\",fixed_down)\n",
    "    #print (\"fixed_up:\",fixed_up)\n",
    "    #print (\"slope_threshold: \",slope_threshold)\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37bd3932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.906051Z",
     "iopub.status.busy": "2025-05-26T10:17:14.905841Z",
     "iopub.status.idle": "2025-05-26T10:17:14.917347Z",
     "shell.execute_reply": "2025-05-26T10:17:14.916745Z"
    },
    "papermill": {
     "duration": 0.018129,
     "end_time": "2025-05-26T10:17:14.918473",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.900344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fast_fix_QRS(signal, mask, fs=250):\n",
    "    # time = np.arange(len(signal)) / fs\n",
    "    # indices = np.arange(len(mask))  # Precompute indices array\n",
    "\n",
    "    # Precompute slopes for QRS start and end adjustments\n",
    "    # slope_start = np.zeros_like(signal)\n",
    "    # slope_start[3:] = signal[3:] - signal[:-3]  # slope[i] = signal[i] - signal[i-3]\n",
    "    slope_end = np.zeros_like(signal)\n",
    "    slope_end[:-5] = signal[:-5] - signal[5:]    # slope[i] = signal[i] - signal[i+5]\n",
    "\n",
    "    # Identify QRS regions (mask == 2)\n",
    "    qrs_mask = (mask == 2).astype(np.int8)\n",
    "    transitions = np.diff(qrs_mask, prepend=0)\n",
    "    qrs_starts = np.flatnonzero(transitions == 1)\n",
    "    qrs_ends = np.flatnonzero(transitions == -1) - 1\n",
    "    n = len(signal)\n",
    "\n",
    "    if len(qrs_ends) < len(qrs_starts):\n",
    "        qrs_ends = np.append(qrs_ends, n - 1)\n",
    "\n",
    "    for i in tqdm(range(len(qrs_starts)), desc=\"Processing QRS\"):\n",
    "        qrs_start = qrs_starts[i]\n",
    "        # next_qrs_start = qrs_starts[i+1] if i < len(qrs_starts)-1 else len(mask)\n",
    "        # Find QRS end within the current segment\n",
    "        qrs_end = qrs_ends[i]\n",
    "        #before_qrs_end = qrs_ends[i-1] if i > 0 else 0\n",
    "        # Adjust QRS start based on preceding P wave\n",
    "        p_indices = np.where(mask[max(0, qrs_start-200):qrs_start] == 1)[0]\n",
    "        valid_p = []\n",
    "        if len(p_indices) > 0:\n",
    "            # Check from the end backwards\n",
    "            p_end = p_indices[-1]\n",
    "            p_end = p_indices[-1]  # just take the last one\n",
    "            if not np.any(mask[p_end:qrs_start] >= 2):  # no QRS or T in between\n",
    "                p_start = p_end\n",
    "                if p_start > 0 and mask[p_start-1] == 1:\n",
    "                    p_start -= 1\n",
    "                valid_p = np.arange(p_start, p_end + 1)\n",
    "                \n",
    "        if len(valid_p) > 0 and (qrs_start - valid_p[-1]) < 20:\n",
    "            # print(\"vaid p, qrs moved back:\",qrs_start-p_end)\n",
    "            mask[p_end+1:qrs_start] = 2\n",
    "            qrs_start = p_end +1\n",
    "        else:\n",
    "            # Precompute signal range before QRS\n",
    "            # print(\"no vaid p\")\n",
    "            \n",
    "            pre_start = max(0, qrs_start - 100)\n",
    "            pre_wave = signal[pre_start:qrs_start]\n",
    "            \n",
    "            # Find first valid peak before QRS\n",
    "            first_peak_before_qrs = None\n",
    "            if len(pre_wave) > 3:\n",
    "                peaks, _ = find_peaks(pre_wave, prominence=0.01)\n",
    "                for p in peaks:\n",
    "                    if mask[pre_start + p] == 0:\n",
    "                        # print(\"found peak before qrs\")\n",
    "                        first_peak_before_qrs = pre_start + p\n",
    "                        break\n",
    "            # Track first peak (if any)\n",
    "\n",
    "                    \n",
    "            original_qrs_start = qrs_start  # save original position\n",
    "            slope_threshold = 0.02\n",
    "            max_back_steps = 25\n",
    "            back_steps = 0\n",
    "        \n",
    "            while back_steps < max_back_steps and qrs_start >= 3:\n",
    "                       \n",
    "                diff_signal = signal[qrs_start] - signal[qrs_start - 3]\n",
    "                if abs(diff_signal) < slope_threshold:\n",
    "                    \n",
    "                    # Dynamic threshold (only if stuck)\n",
    "                    if back_steps == 0 and slope_threshold>0.005:\n",
    "                        slope_threshold = max(slope_threshold - 0.001, 0.005)\n",
    "                        continue \n",
    "                    break\n",
    "        \n",
    "                if first_peak_before_qrs is not None and qrs_start <= first_peak_before_qrs:\n",
    "                    break\n",
    "        \n",
    "                if mask[qrs_start - 1] != 0:\n",
    "                    break\n",
    "        \n",
    "                # Move QRS start backward\n",
    "                qrs_start -= 1\n",
    "                back_steps += 1\n",
    "        \n",
    "            \n",
    "            mask[qrs_start:original_qrs_start] = 2\n",
    "            # print(\"vaid p, qrs moved back:\",original_qrs_start-qrs_start)\n",
    "            \n",
    "        # Adjust QRS end\n",
    "        # Extend until signal stops descending\n",
    "        original_qrs_end = qrs_end\n",
    "        while qrs_end < len(signal)-1 and mask[qrs_end+1] == 0 and signal[qrs_end] >= signal[qrs_end+1]:\n",
    "            qrs_end += 1\n",
    "        \n",
    "        # Vectorize the mask update to do it all at once\n",
    "        mask[original_qrs_end:qrs_end+1] = 2\n",
    "\n",
    "        # Further adjust based on slope\n",
    "        slope_threshold_end = 0.02\n",
    "        max_forward_steps = 25\n",
    "        forward_steps = 0\n",
    "        # print(\"vaid p, qrs moved back:\",original_qrs_start-qrs_start)\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "            while (qrs_end < len(signal)-5 \n",
    "                   and forward_steps < max_forward_steps \n",
    "                   and abs(slope_end[qrs_end]) >= slope_threshold_end \n",
    "                   and mask[qrs_end+1] == 0):\n",
    "                qrs_end += 1\n",
    "                forward_steps += 1\n",
    "            if abs(slope_end[qrs_end]) < slope_threshold_end and forward_steps == 0 and slope_threshold_end>0.005: \n",
    "                slope_threshold_end = max(slope_threshold_end - 0.001, 0.005)\n",
    "                continue\n",
    "            else :\n",
    "                mask[qrs_end - forward_steps + 1: qrs_end + 1] = 2\n",
    "                break\n",
    "                                \n",
    "            \n",
    "        \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aae7186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.929483Z",
     "iopub.status.busy": "2025-05-26T10:17:14.929290Z",
     "iopub.status.idle": "2025-05-26T10:17:14.934755Z",
     "shell.execute_reply": "2025-05-26T10:17:14.934071Z"
    },
    "id": "b8dM91RXhegF",
    "outputId": "251c71b8-b899-4008-b25b-cde66a81fdc2",
    "papermill": {
     "duration": 0.012847,
     "end_time": "2025-05-26T10:17:14.935838",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.922991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 2 0 3 3 3 3 3 3 3 3 3 3 3 0 0 0 1 1 0\n",
      " 0 2 2 0 3 3 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def post_process_ecg(predicted):\n",
    "\n",
    "    predicted = remove_uncomplete_first_last_wave(predicted)\n",
    "    predicted = merge_close_waves(predicted)\n",
    "    predicted = remove_irrelevant_waves(predicted)\n",
    "    predicted = check_repeated_waves(predicted)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "predicted = np.array([1,1,0, 1, 1, 0,0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 2, 2, 0, 3, 3, 0,0,0,0,0,0,3, 3, 3, 0,0,0,1, 1, 0, 0, 2, 2, 0, 3, 3,0,3,3])\n",
    "predicted = post_process_ecg(predicted)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046f2af",
   "metadata": {
    "id": "IsKW-178f8s7",
    "papermill": {
     "duration": 0.004622,
     "end_time": "2025-05-26T10:17:14.944883",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.940261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1990f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:14.955184Z",
     "iopub.status.busy": "2025-05-26T10:17:14.954908Z",
     "iopub.status.idle": "2025-05-26T10:17:19.055588Z",
     "shell.execute_reply": "2025-05-26T10:17:19.055047Z"
    },
    "id": "a07tScN96T4a",
    "papermill": {
     "duration": 4.107794,
     "end_time": "2025-05-26T10:17:19.057041",
     "exception": false,
     "start_time": "2025-05-26T10:17:14.949247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualConvBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3,\n",
    "                              padding=dilation, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3,\n",
    "                               padding=dilation, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv1d(F_g, F_int, kernel_size=1),\n",
    "            nn.BatchNorm1d(F_int)\n",
    "        )\n",
    "\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv1d(F_l, F_int, kernel_size=1),\n",
    "            nn.BatchNorm1d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv1d(F_int, 1, kernel_size=1),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class UNet1D_Enhanced(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=4, base_filters=64):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder with residual blocks and multi-scale context\n",
    "        self.enc1 = ResidualConvBlock1D(in_channels, base_filters)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.enc2 = ResidualConvBlock1D(base_filters, base_filters*2)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.enc3 = ResidualConvBlock1D(base_filters*2, base_filters*4)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.enc4 = ResidualConvBlock1D(base_filters*4, base_filters*8)\n",
    "        self.pool4 = nn.MaxPool1d(2)\n",
    "\n",
    "        # Bottleneck with dilated convolution\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ResidualConvBlock1D(base_filters*8, base_filters*16, dilation=2),\n",
    "            ResidualConvBlock1D(base_filters*16, base_filters*16, dilation=4)\n",
    "        )\n",
    "\n",
    "        # Decoder with attention gates\n",
    "        self.upconv4 = nn.ConvTranspose1d(base_filters*16, base_filters*8, kernel_size=2, stride=2)\n",
    "        self.att4 = AttentionBlock(base_filters*8, base_filters*8, base_filters//2)\n",
    "        self.dec4 = ResidualConvBlock1D(base_filters*16, base_filters*8)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose1d(base_filters*8, base_filters*4, kernel_size=2, stride=2)\n",
    "        self.att3 = AttentionBlock(base_filters*4, base_filters*4, base_filters//4)\n",
    "        self.dec3 = ResidualConvBlock1D(base_filters*8, base_filters*4)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose1d(base_filters*4, base_filters*2, kernel_size=2, stride=2)\n",
    "        self.att2 = AttentionBlock(base_filters*2, base_filters*2, base_filters//8)\n",
    "        self.dec2 = ResidualConvBlock1D(base_filters*4, base_filters*2)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose1d(base_filters*2, base_filters, kernel_size=2, stride=2)\n",
    "        self.att1 = AttentionBlock(base_filters, base_filters, base_filters//16)\n",
    "        self.dec1 = ResidualConvBlock1D(base_filters*2, base_filters)\n",
    "\n",
    "        # Output with multi-scale feature fusion\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv1d(base_filters, base_filters//2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(base_filters//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(base_filters//2, n_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        # Boundary refinement\n",
    "        self.boundary_refine = nn.Conv1d(n_classes, n_classes, kernel_size=5, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        e4 = self.enc4(self.pool3(e3))\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool4(e4))\n",
    "\n",
    "        # Decoder with attention\n",
    "        d4 = self.upconv4(b)\n",
    "        e4 = self.att4(d4, center_crop(e4, d4.shape[-1]))\n",
    "        d4 = self.dec4(torch.cat([d4, e4], dim=1))\n",
    "\n",
    "        d3 = self.upconv3(d4)\n",
    "        e3 = self.att3(d3, center_crop(e3, d3.shape[-1]))\n",
    "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        e2 = self.att2(d2, center_crop(e2, d2.shape[-1]))\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        e1 = self.att1(d1, center_crop(e1, d1.shape[-1]))\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
    "\n",
    "        # Output\n",
    "        out = self.final_conv(d1)\n",
    "\n",
    "        # Boundary refinement\n",
    "        out = out + self.boundary_refine(out)  # Residual connection\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def center_crop(enc_feat, target_size):\n",
    "    _, _, L = enc_feat.size()\n",
    "    diff = L - target_size\n",
    "    if diff == 0:\n",
    "        return enc_feat\n",
    "    elif diff < 0:\n",
    "        raise ValueError(\"Encoder feature shorter than target\")\n",
    "    start = diff // 2\n",
    "    end = start + target_size\n",
    "    return enc_feat[:, :, start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4143d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:19.067928Z",
     "iopub.status.busy": "2025-05-26T10:17:19.067539Z",
     "iopub.status.idle": "2025-05-26T10:17:20.115575Z",
     "shell.execute_reply": "2025-05-26T10:17:20.114811Z"
    },
    "id": "Kjq9YZXZQbLl",
    "outputId": "3d9aecce-4247-4762-cfcb-817d4398b7a7",
    "papermill": {
     "duration": 1.054854,
     "end_time": "2025-05-26T10:17:20.116780",
     "exception": false,
     "start_time": "2025-05-26T10:17:19.061926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2491763897.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_deep.load_state_dict(torch.load(\"/kaggle/input/unet-model-for-ecg-mask-detection/pytorch/default/1/updated_unet1d_ecg_qrs.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet1D_Enhanced(\n",
       "  (enc1): ResidualConvBlock1D(\n",
       "    (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(1, 64, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (enc2): ResidualConvBlock1D(\n",
       "    (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (enc3): ResidualConvBlock1D(\n",
       "    (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (enc4): ResidualConvBlock1D(\n",
       "    (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleneck): Sequential(\n",
       "    (0): ResidualConvBlock1D(\n",
       "      (conv1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "      (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "      (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualConvBlock1D(\n",
       "      (conv1): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "      (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "      (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (upconv4): ConvTranspose1d(1024, 512, kernel_size=(2,), stride=(2,))\n",
       "  (att4): AttentionBlock(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (dec4): ResidualConvBlock1D(\n",
       "    (conv1): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv3): ConvTranspose1d(512, 256, kernel_size=(2,), stride=(2,))\n",
       "  (att3): AttentionBlock(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv1d(256, 16, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv1d(256, 16, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (dec3): ResidualConvBlock1D(\n",
       "    (conv1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv2): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))\n",
       "  (att2): AttentionBlock(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv1d(128, 8, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv1d(128, 8, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv1d(8, 1, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (dec2): ResidualConvBlock1D(\n",
       "    (conv1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (upconv1): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))\n",
       "  (att1): AttentionBlock(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv1d(64, 4, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv1d(64, 4, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv1d(4, 1, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (dec1): ResidualConvBlock1D(\n",
       "    (conv1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Sequential(\n",
       "    (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv1d(32, 4, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (boundary_refine): Conv1d(4, 4, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize model\n",
    "model_deep = UNet1D_Enhanced(n_classes=4).to(device)\n",
    "model_deep.load_state_dict(torch.load(\"/kaggle/input/unet-model-for-ecg-mask-detection/pytorch/default/1/updated_unet1d_ecg_qrs.pth\", map_location=device))\n",
    "model_deep.to(device)\n",
    "model_deep.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f255aab0",
   "metadata": {
    "id": "uWCRAJaggYfb",
    "papermill": {
     "duration": 0.00515,
     "end_time": "2025-05-26T10:17:20.127404",
     "exception": false,
     "start_time": "2025-05-26T10:17:20.122254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085c2da",
   "metadata": {
    "id": "7l6N9wIkOUkH",
    "papermill": {
     "duration": 0.004925,
     "end_time": "2025-05-26T10:17:20.137224",
     "exception": false,
     "start_time": "2025-05-26T10:17:20.132299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# making dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81523053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:20.148393Z",
     "iopub.status.busy": "2025-05-26T10:17:20.147796Z",
     "iopub.status.idle": "2025-05-26T10:17:20.154516Z",
     "shell.execute_reply": "2025-05-26T10:17:20.153930Z"
    },
    "id": "RxQOkRn132tk",
    "papermill": {
     "duration": 0.013341,
     "end_time": "2025-05-26T10:17:20.155519",
     "exception": false,
     "start_time": "2025-05-26T10:17:20.142178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_and_save_mask(record_name, path, model, start=None, end=None, target_fs=250, save_path=\"masks/\"):\n",
    "    record = wfdb.rdrecord(path)\n",
    "    signal = record.p_signal[:, 0]  # lead I\n",
    "    fs = record.fs\n",
    "\n",
    "    if end is None:\n",
    "        end = len(signal) / fs\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    signal = signal[int(start*fs):int(end*fs)]\n",
    "\n",
    "    if fs != 250:\n",
    "        signal = resample_signal(signal, original_fs=fs, target_fs=target_fs)\n",
    "        fs = target_fs\n",
    "\n",
    "    # Predict\n",
    "    pred_labels, segments, _ = predict_full_ecg(signal, model, fs=fs)\n",
    "    signal = np.concatenate(segments, axis=2).reshape(-1)\n",
    "\n",
    "    # Post-process mask\n",
    "    pred_labels = remove_uncomplete_first_last_wave(pred_labels)\n",
    "    pred_labels = merge_close_waves(pred_labels)\n",
    "    pred_labels = remove_irrelevant_waves(pred_labels)\n",
    "    pred_labels = check_repeated_waves(pred_labels)\n",
    "    pred_labels = fix_P(signal, pred_labels)\n",
    "    pred_labels = fast_fix_QRS(signal, pred_labels, fs=fs)\n",
    "    pred_labels = merge_close_waves(pred_labels)\n",
    "\n",
    "    # Save mask\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    mask_filename = os.path.join(save_path, f\"{record_name}_mask.csv\")\n",
    "\n",
    "    # Save the file\n",
    "    os.makedirs(os.path.dirname(mask_filename), exist_ok=True)\n",
    "    np.savetxt(mask_filename, pred_labels, delimiter=\",\", fmt=\"%d\")\n",
    "    print(f\"Saved mask to: {mask_filename}\")\n",
    "    return mask_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8c7f3a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:20.166227Z",
     "iopub.status.busy": "2025-05-26T10:17:20.165989Z",
     "iopub.status.idle": "2025-05-26T10:17:20.171859Z",
     "shell.execute_reply": "2025-05-26T10:17:20.171116Z"
    },
    "id": "Vp0n6IPwN60K",
    "papermill": {
     "duration": 0.012573,
     "end_time": "2025-05-26T10:17:20.172940",
     "exception": false,
     "start_time": "2025-05-26T10:17:20.160367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import contextlib\n",
    "from functools import partial\n",
    "import sys\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_output():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = devnull\n",
    "        sys.stderr = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "# Patch tqdm globally if needed\n",
    "silent_tqdm = partial(tqdm, disable=True)\n",
    "\n",
    "def batch_predict_masks(mitdb_path, mit_records, model, target_fs=250):\n",
    "    \n",
    "    all_dfs = []\n",
    "\n",
    "    #for record_name in tqdm(mit_records, total=len(mit_records), desc=\"Processing mit_records\"):\n",
    "    for record_name in tqdm( mit_records, total=len(mit_records), desc=\"mask detection\"):\n",
    "        full_path = os.path.join(mitdb_path, record_name)\n",
    "        with suppress_output():\n",
    "            df = predict_and_save_mask(str(record_name), full_path, model, target_fs=250)   \n",
    "            \n",
    "\n",
    "    return all_dfs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ed26bb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:20.183548Z",
     "iopub.status.busy": "2025-05-26T10:17:20.183007Z",
     "iopub.status.idle": "2025-05-26T10:17:20.253558Z",
     "shell.execute_reply": "2025-05-26T10:17:20.252791Z"
    },
    "papermill": {
     "duration": 0.07694,
     "end_time": "2025-05-26T10:17:20.254642",
     "exception": false,
     "start_time": "2025-05-26T10:17:20.177702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48,105 records.\n",
      "List['109', '118', '124', '104', '215', '119', '112', '223', '116', '203', '106', '212', '122', '230', '100', '121', '234', '214', '210', '107', '102', '233', '201', '222', '219', '217', '200', '123', '202', '108', '111', '213', '113', '228', '208', '231', '114', '220', '221', '101', '205', '103', '232', '105', '207', '209', '117', '115']\n",
      "['100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '111', '112', '113', '114', '115', '116', '117', '118', '119', '121', '122', '123', '124', '200', '201', '202', '203', '205', '207', '208', '209', '210', '212', '213', '214', '215', '217', '219', '220', '221', '222', '223', '228', '230', '231', '232', '233', '234']\n",
      "['sel100', 'sel102', 'sel103', 'sel104', 'sel114', 'sel116', 'sel117', 'sel123', 'sel14046', 'sel14157', 'sel14172', 'sel15814', 'sel16265', 'sel16272', 'sel16273', 'sel16420', 'sel16483', 'sel16539', 'sel16773', 'sel16786', 'sel16795', 'sel17152', 'sel17453', 'sel213', 'sel221', 'sel223', 'sel230', 'sel231', 'sel232', 'sel233', 'sel30', 'sel301', 'sel302', 'sel306', 'sel307', 'sel308', 'sel31', 'sel310', 'sel32', 'sel33', 'sel34', 'sel35', 'sel36', 'sel37', 'sel38', 'sel39', 'sel40', 'sel41', 'sel42', 'sel43', 'sel44', 'sel45', 'sel46', 'sel47', 'sel48', 'sel49', 'sel50', 'sel51', 'sel52', 'sel803', 'sel808', 'sel811', 'sel820', 'sel821', 'sel840', 'sel847', 'sel853', 'sel871', 'sel872', 'sel873', 'sel883', 'sel891', 'sele0104', 'sele0106', 'sele0107', 'sele0110', 'sele0111', 'sele0112', 'sele0114', 'sele0116', 'sele0121', 'sele0122', 'sele0124', 'sele0126', 'sele0129', 'sele0133', 'sele0136', 'sele0166', 'sele0170', 'sele0203', 'sele0210', 'sele0211', 'sele0303', 'sele0405', 'sele0406', 'sele0409', 'sele0411', 'sele0509', 'sele0603', 'sele0604', 'sele0606', 'sele0607', 'sele0609', 'sele0612', 'sele0704']\n"
     ]
    }
   ],
   "source": [
    "#mit_records = ['123']\n",
    "import os\n",
    "def get_all_records(directory, extension=\".dat\"):\n",
    "    files = [f.replace(extension, \"\") for f in os.listdir(directory) if f.endswith(extension)]\n",
    "    return list(set(files))  # Ensure no duplicates\n",
    "\n",
    "\n",
    "mitdb_path = \"/kaggle/input/qtdb-ludb/physionet.org/files/mitdb/1.0.0/\"\n",
    "qtdb_path = \"/kaggle/input/qtdb-ludb/physionet.org/files/qtdb/1.0.0\"\n",
    "mit_records = get_all_records(mitdb_path)\n",
    "qtdb_records = get_all_records(qtdb_path)\n",
    "\n",
    "print(f\"Found {len(mit_records)},{len(qtdb_records)} records.\")\n",
    "print(f\"List{mit_records}\")\n",
    "mit_records.sort()\n",
    "qtdb_records.sort()\n",
    "print(mit_records)\n",
    "print(qtdb_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dc8b216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T10:17:20.265514Z",
     "iopub.status.busy": "2025-05-26T10:17:20.265333Z",
     "iopub.status.idle": "2025-05-26T10:44:39.154864Z",
     "shell.execute_reply": "2025-05-26T10:44:39.154051Z"
    },
    "id": "D-S5WHnjN70v",
    "outputId": "0e67fd46-3a81-4818-c0a6-ecb61462fb76",
    "papermill": {
     "duration": 1638.897065,
     "end_time": "2025-05-26T10:44:39.156743",
     "exception": false,
     "start_time": "2025-05-26T10:17:20.259678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mask detection: 100%|██████████| 105/105 [13:34<00:00,  7.76s/it]\n",
      "mask detection: 100%|██████████| 48/48 [13:44<00:00, 17.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# 123 fast\n",
    "df_all = batch_predict_masks(qtdb_path, qtdb_records, model_deep)\n",
    "df_all = batch_predict_masks(mitdb_path, mit_records, model_deep)\n",
    "# 1789/2655\n",
    "    # /kaggle/input/qtdb-ludb/physionet.org/files/qtdb/1.0.0/sel30.atr"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jvXrP01oftqo",
    "ZW-HQbGIN86a",
    "UCgs5n5KgSse",
    "IsKW-178f8s7"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7030512,
     "sourceId": 11264306,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 355945,
     "modelInstanceId": 334922,
     "sourceId": 410120,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 326399,
     "modelInstanceId": 305955,
     "sourceId": 412634,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1659.00276,
   "end_time": "2025-05-26T10:44:41.746263",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-26T10:17:02.743503",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
